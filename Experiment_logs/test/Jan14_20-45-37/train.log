Running with parameters: 
  action: train
  name: test
  modality: ['RGB']
  total_batch: 128
  batch_size: 32
  gpus: None
  wandb_name: None
  resume_from: None
  logname: None
  models_dir: saved_models/test/Jan14_20-45-37
  train:
    num_iter: 5000
    lr_steps: 3000
    eval_freq: 50
    num_clips: 1
    dense_sampling:
      RGB: True
    num_frames_per_clip:
      RGB: 16
  test:
    num_clips: 5
    dense_sampling:
      RGB: True
    num_frames_per_clip:
      RGB: 16
  dataset:
    annotations_path: train_val
    shift: D1-D1
    workers: 4
    stride: 2
    resolution: 224
    RGB:
      data_path: ../ek_data/frames
      tmpl: img_{:010d}.jpg
      features_name: test_feat_kinetics
    Event:
      rgb4e: 6
  models:
    RGB:
      model: Classifier
      normalize: False
      kwargs:
      lr_steps: 3000
      lr: 0.01
      sgd_momentum: 0.9
      weight_decay: 1e-07
  experiment_dir: test/Jan14_20-45-37
  log_dir: Experiment_logs/test/Jan14_20-45-37
  logfile: Experiment_logs/test/Jan14_20-45-37/train.log
Instantiating models per modality
Classifier Net	Modality: RGB
Dataloader for D1-train with 1543 samples generated
Dataloader for D1-val with 435 samples generated
Iteration 0/20000 batch retrieved! Elapsed time = 0.0 m 0.13519 s
Uncaught exception
Traceback (most recent call last):
  File "/content/aml23-ego/train_classifier.py", line 250, in <module>
    main()
  File "/content/aml23-ego/train_classifier.py", line 87, in main
    train(action_classifier, train_loader, val_loader, device, num_classes)
  File "/content/aml23-ego/train_classifier.py", line 154, in train
    logits, _ = action_classifier.forward(data)
  File "/content/aml23-ego/tasks/action_recognition_task.py", line 77, in forward
    logits[m], feat = self.task_models[m](x=data[m], **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py", line 183, in forward
    return self.module(*inputs[0], **module_kwargs[0])
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/content/aml23-ego/models/FinalClassifier.py", line 20, in forward
    return self.classifier(x), {}
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x1024 and 5120x512)
